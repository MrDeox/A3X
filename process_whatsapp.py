import os\nimport re\nimport json\nimport logging\nfrom datetime import datetime\n\n# --- Configuration ---\n# Set ARTHUR_SENDER_NAME to the exact name used in the logs\n# Assuming the name is 'Arthur' based on context.\n# If different in the logs, please change this value manually.\nARTHUR_SENDER_NAME = "Arthur"\n\nWHATSAPP_EXPORTS_DIR = os.path.join("data", "whatsapp_exports")\nOUTPUT_DATASET_PATH = os.path.join("data", "arthur_decision_dataset.jsonl")\n\n# Regex to capture typical WhatsApp lines (adjust based on actual format)\n# Handles formats like: DD/MM/YYYY, HH:MM - Sender Name: Message\n#                 or: MM/DD/YY, HH:MM - Sender Name: Message\n# It assumes sender names don't contain \':\' right after the name.\n# It captures timestamp, sender, and message content.\n# Modified to handle potential variations in date/time format and sender name\nLINE_REGEX = re.compile(r"^(\d{1,2}/\d{1,2}/\d{2,4},\s+\d{1,2}:\d{2})\s+-\s+([^:]+):\s+(.*)")\n\n# Setup logging\nlogging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\nlogger = logging.getLogger(__name__)\n\n# --- Helper Functions ---\n\ndef parse_line(line):\n    """Parses a single line using regex. Returns (timestamp_str, sender, message) or None."""\n    match = LINE_REGEX.match(line)\n    if match:\n        timestamp_str, sender, message = match.groups()\n        # Basic cleaning\n        sender = sender.strip()\n        message = message.strip()\n        return timestamp_str, sender, message\n    return None\n\ndef append_to_jsonl(filepath, data_record):\n    """Appends a dictionary as a JSON line to the specified file."""\n    try:\n        with open(filepath, 'a', encoding='utf-8') as f:\n            json.dump(data_record, f, ensure_ascii=False)\n            f.write('\n')\n    except Exception as e:\n        logger.error(f"Failed to write record to {filepath}: {e}")\n\n# --- Main Processing Logic ---\n\ndef process_whatsapp_exports(exports_dir, output_path, arthur_name):\n    """Processes all .txt files in the exports directory and saves to JSONL."""\n    logger.info("Starting WhatsApp export processing...")\n    logger.info(f"Input directory: {exports_dir}")\n    logger.info(f"Output file: {output_path}")\n    logger.info(f"Identifying Arthur's messages by sender name: '{arthur_name}'")\n\n    if not os.path.isdir(exports_dir):\n        logger.error(f"Input directory not found: {exports_dir}")\n        return\n\n    # Clear the output file if it exists\n    if os.path.exists(output_path):\n        logger.warning(f"Output file {output_path} already exists. Overwriting.")\n        try:\n            os.remove(output_path)\n        except OSError as e:\n            logger.error(f"Could not remove existing output file: {e}")\n            return\n\n    processed_records = 0\n    total_files = 0\n\n    for filename in os.listdir(exports_dir):\n        if filename.endswith(".txt"):\n            total_files += 1\n            file_path = os.path.join(exports_dir, filename)\n            logger.info(f"Processing file: {filename}...")\n\n            current_input_messages = []\n            last_sender = None\n            consecutive_other_messages = []\n\n            try:\n                with open(file_path, 'r', encoding='utf-8') as f:\n                    for line_num, line in enumerate(f, 1):\n                        line = line.strip()\n                        if not line:\n                            continue\n\n                        parsed = parse_line(line)\n\n                        if parsed:\n                            timestamp_str, sender, message = parsed\n                            # logger.debug(f"Parsed Line {line_num}: S={sender}, M={message[:50]}...")\n\n                            # Message from Arthur\n                            if sender == arthur_name:\n                                # If there were preceding messages from others, create a record\n                                if consecutive_other_messages:\n                                    input_text = "\n".join([m['message'] for m in consecutive_other_messages])\n                                    context = { # Store more context if needed\n                                        "source_file": filename,\n                                        "first_input_timestamp": consecutive_other_messages[0]['timestamp'],\n                                        "last_input_timestamp": consecutive_other_messages[-1]['timestamp'],\n                                        "input_senders": list(set(m['sender'] for m in consecutive_other_messages))\n                                    }\n                                    record = {\n                                        "input": input_text,\n                                        # "context": context, # Optional: Add more structured context\n                                        "arthur_response": message,\n                                        "source": f"{filename}#L{line_num}", # Track source line\n                                        "timestamp": timestamp_str # Timestamp of Arthur's response\n                                    }\n                                    append_to_jsonl(output_path, record)\n                                    processed_records += 1\n                                    # logger.debug(f"Created record: Input={input_text[:50]}... -> Response={message[:50]}...")\n\n                                # Reset for the next interaction\n                                consecutive_other_messages = []\n                            # Message from someone else\n                            else:\n                                consecutive_other_messages.append({\n                                    "timestamp": timestamp_str,\n                                    "sender": sender,\n                                    "message": message\n                                })\n\n                            last_sender = sender\n                        # Handle multi-line messages (append to the last parsed message)\n                        elif last_sender is not None and consecutive_other_messages: # Append to last *other* message\n                             # Only append if the last message was from someone else\n                             if consecutive_other_messages[-1]['sender'] != arthur_name:\n                                  consecutive_other_messages[-1]['message'] += "\n" + line\n                        # else: # Could be media omitted message or system message - ignore for now\n                            # logger.debug(f"Skipping unparsed line {line_num}: {line}")\n\n            except Exception as e:\n                logger.error(f"Error processing file {filename}: {e}", exc_info=True)\n\n    logger.info(f"Finished processing {total_files} file(s).")\n    logger.info(f"Total records generated: {processed_records}")\n    logger.info(f"Output dataset saved to: {output_path}")\n\nif __name__ == "__main__":\n    # Check if the name is still the default, warn if so.\n    # No longer exiting automatically, just warning.\n    if ARTHUR_SENDER_NAME == "Arthur": # Default value check\n        logger.warning("ARTHUR_SENDER_NAME is using the default value 'Arthur'. If this is not correct for your logs, please edit the script.")\n\n    process_whatsapp_exports(WHATSAPP_EXPORTS_DIR, OUTPUT_DATASET_PATH, ARTHUR_SENDER_NAME) 