# a3x/core/data_collector/build_dataset.py\n\n# <<< FORCE EXCEPTION FOR DEBUGGING >>>\n# <<< END FORCE EXCEPTION >>>\n\n\"\"\"Orchestrates data collection from multiple sources and builds the final dataset.\"\"\"\n\nimport json\nimport os\nimport datetime\n\n# Import the specific collectors\nprint("--- BUILD_DATASET: Importing collectors...")\nfrom .collect_whatsapp import WhatsAppCollector\nfrom .collect_browser import BrowserCollector\nfrom .collect_markdown import MarkdownCollector\nfrom .collect_github import GitHubCollector\nprint("--- BUILD_DATASET: Collectors imported.")\n\n# --- Configuration (Paths relative to project root) ---\nDATA_DIR = "data"\nOUTPUT_DATASET_PATH = os.path.join(DATA_DIR, "arthur_decision_dataset.jsonl")\n\n# Paths to your data sources (relative to project root)\nWHATSAPP_EXPORT_DIR = os.path.join(DATA_DIR, "whatsapp_exports") # <--- Pasta para colocar os .txt exportados\nMARKDOWN_DOCS_DIR = "docs"                                      # <--- DiretÃ³rio dos seus documentos\nGITHUB_REPOS = ['ArthurReiner/A3X'] # Example list of your relevant repos\nGITHUB_TOKEN = os.getenv("GITHUB_TOKEN") # Recommended way to handle token\n# --- End Configuration ---\n\n# --- Main Orchestration Function ---\ndef build_dataset(output_path=OUTPUT_DATASET_PATH):\n    \"\"\"Runs all configured collectors and saves the aggregated dataset.\"\"\"\n    all_records = []\n    # Ensure output directory exists\n    print(f"--- BUILD_DATASET: Ensuring output directory exists: {os.path.dirname(output_path)} ---")\n    os.makedirs(os.path.dirname(output_path), exist_ok=True)\n\n    print(f"Starting dataset build. Output target: {output_path}")\n\n    # 1. WhatsApp Collector\n    print(f"\n--- BUILD_DATASET: Running WhatsApp Collector --- ")\n    print(f"--- BUILD_DATASET: Checking directory: {WHATSAPP_EXPORT_DIR} ---")\n    if os.path.isdir(WHATSAPP_EXPORT_DIR): # Check if directory exists\n        try:\n            print("--- BUILD_DATASET: Instantiating WhatsAppCollector ---")\n            wa_collector = WhatsAppCollector() # Assumes YOUR_NAME is set inside collect_whatsapp.py\n            print("--- BUILD_DATASET: Calling WhatsAppCollector.collect... ---")\n            wa_records = wa_collector.collect(WHATSAPP_EXPORT_DIR) # Pass directory path\n            print(f"--- BUILD_DATASET: WhatsAppCollector finished, received {len(wa_records)} records ---")\n            all_records.extend(wa_records)\n            print(f"Collected {len(wa_records)} records from WhatsApp.")\n        except Exception as e:\n            print(f"--- BUILD_DATASET: ERROR during WhatsApp collection: {e} ---")\n    else:\n        print(f"WhatsApp export directory not found at {WHATSAPP_EXPORT_DIR}. Skipping.")\n        print("Please create the directory and place your exported .txt files there.")\n\n    # 2. Browser Collector\n    print(f"\n--- BUILD_DATASET: Running Browser Collector (Firefox) --- ")\n    try:\n        print("--- BUILD_DATASET: Instantiating BrowserCollector ---")\n        browser_collector = BrowserCollector()\n        # Collect last 90 days from Firefox as an example\n        print("--- BUILD_DATASET: Calling BrowserCollector.collect... ---")\n        browser_records = browser_collector.collect(browser='firefox', time_limit_days=90)\n        print(f"--- BUILD_DATASET: BrowserCollector finished, received {len(browser_records)} records ---")\n        all_records.extend(browser_records)\n        print(f"Collected {len(browser_records)} records from Browser.")\n    except Exception as e:\n         print(f"--- BUILD_DATASET: ERROR during Browser collection: {e} ---")\n\n    # 3. Markdown Collector\n    print(f"\n--- BUILD_DATASET: Running Markdown Collector --- ")\n    print(f"--- BUILD_DATASET: Checking directory: {MARKDOWN_DOCS_DIR} ---")\n    if os.path.isdir(MARKDOWN_DOCS_DIR):\n        try:\n            print("--- BUILD_DATASET: Instantiating MarkdownCollector ---")\n            md_collector = MarkdownCollector()\n            print("--- BUILD_DATASET: Calling MarkdownCollector.collect... ---")\n            md_records = md_collector.collect(MARKDOWN_DOCS_DIR)\n            print(f"--- BUILD_DATASET: MarkdownCollector finished, received {len(md_records)} records ---")\n            all_records.extend(md_records)\n            print(f"Collected {len(md_records)} records from Markdown ({MARKDOWN_DOCS_DIR}).")\n        except Exception as e:\n            print(f"--- BUILD_DATASET: ERROR during Markdown collection: {e} ---")\n    else:\n        print(f"Markdown directory not found at {MARKDOWN_DOCS_DIR}. Skipping.")\n\n    # 4. GitHub Collector\n    print(f"\n--- BUILD_DATASET: Running GitHub Collector (Placeholder) --- ")\n    try:\n        print("--- BUILD_DATASET: Instantiating GitHubCollector ---")\n        gh_collector = GitHubCollector(api_token=GITHUB_TOKEN)\n        # Collect commits, issues, PRs from the last 90 days\n        print("--- BUILD_DATASET: Calling GitHubCollector.collect... ---")\n        gh_records = gh_collector.collect(repo_list=GITHUB_REPOS, time_limit_days=90)\n        print(f"--- BUILD_DATASET: GitHubCollector finished, received {len(gh_records)} records ---")\n        all_records.extend(gh_records)\n        print(f"Collected {len(gh_records)} records from GitHub (Placeholder).")\n    except Exception as e:\n        print(f"--- BUILD_DATASET: ERROR during GitHub collection: {e} ---")\n\n    # --- Save the aggregated dataset --- \n    print(f"\nTotal records collected: {len(all_records)}")\n    if not all_records:\n        print("No records collected. Nothing to save.")\n        return\n\n    print(f"Saving dataset to {output_path}...")\n    try:\n        with open(output_path, 'w', encoding='utf-8') as f:\n            for i, record in enumerate(all_records):\n                # Ensure JSON serializability (datetime handled in BaseCollector)\n                json.dump(record, f, ensure_ascii=False)\n                f.write('\n')\n        print(f"Dataset saved successfully. {i+1} records written.")\n    except Exception as e:\n        print(f"Error saving dataset to {output_path}: {e}")\n\n# --- Run the build process ---\nif __name__ == '__main__':\n    print("--- BUILD_DATASET: __main__ block starting ---")\n    # Attempt to change to project root if running via python -m\n    script_dir = os.path.dirname(os.path.abspath(__file__))\n    project_root = os.path.dirname(os.path.dirname(script_dir)) # Assumes script is in a3x/core/data_collector\n    try:\n        os.chdir(project_root)\n        print(f"--- BUILD_DATASET: Working directory set to project root: {os.getcwd()} ---")\n    except Exception as e:\n        print(f"--- BUILD_DATASET: Warning: Could not change to project root {project_root}: {e}. Assuming running from root.")\n         \n    print("======================================")\n    print("Building Arthur Decision Dataset..."+ \n          " (Ensure data sources are configured correctly)")\n    print("======================================")\n    build_dataset()\n    print("======================================")\n    print("Dataset build process finished.")\n    print("======================================")\n 